{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T20:15:32.973574Z",
     "start_time": "2017-12-06T20:15:32.946773Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what I want is a set of variables that will provide a maximum percentage accuracy increase with the lowest\n",
    "# number of iterations\n",
    "\n",
    "# what if I took what I have and changed it to a conv1d for masking. \n",
    "\n",
    "# could give a softmax of num iters over the difference trainable layer indices\n",
    "# could also give the lr number\n",
    "# \n",
    "\n",
    "# the maximum percentage accuracy increase is the average of all increases from random actions, \n",
    "\n",
    "\n",
    "# iter_budget = 10\n",
    "\n",
    "# example softmax [.2, .2, .2, .2, .2]\n",
    "# all layers would train for 2 iterations each\n",
    "\n",
    "# do I want it to be able to train multiple layers at once? in theory you could replicating training all at once\n",
    "# through doing 1 iteration each for \n",
    "\n",
    "# no you couldnt since it is like freezing everything\n",
    "# I am going under the assumption however that training one layer at a time would be close to as good.\n",
    "# at least for tweaking existing models it should be pretty effective\n",
    "\n",
    "# could have a sequence of layers that are either trained or not trained, and they have\n",
    "\n",
    "\n",
    "# basically we need to choose whether or not to train a layer. the less which are marked to be trained \n",
    "# the less computation it requires.\n",
    "# solving the lr issue would be great\n",
    "\n",
    "\n",
    "# what do we want the input to be\n",
    "# we want it to be all of the trainable layers\n",
    "# could have a 2dconv which analyzes it\n",
    "\n",
    "# layer_dict[\"idx\"] = np.random.choice(trainable_indices)\n",
    "# layer_dict[\"lr\"] = np.random.uniform(1e-1, 1e-6)\n",
    "# layer_dict[\"iters\"] = np.random.randint(0, 3)\n",
    "# layer_dict[\"acc\"] = train(layer_dict)\n",
    "\n",
    "# test = [\n",
    "# # lr, train, conv/dense, magnitude \n",
    "# np.asarray([np.random.uniform(1e-1, 1e-6), np.random.choice([0, 1]), np.random.choice([0, 1]), 10]),\n",
    "# np.asarray([np.random.uniform(1e-1, 1e-6), np.random.choice([0, 1]), np.random.choice([0, 1]), 10])\n",
    "# ]\n",
    "# var = np.asarray(test); var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T20:15:33.623661Z",
     "start_time": "2017-12-06T20:15:19.516Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Idea: LSTM that chooses which layer to train next and with what parameter settings. Could have it be for a set\n",
    "# number of iterations to reduce the overhead. could pass in a conv2d feature extraction for use\n",
    "\n",
    "# iters is number of times trained\n",
    "# highest iters are trained before other modules come in\n",
    "# also could have all iters be indepedent\n",
    "# could have it be an option for the lstm\n",
    "\n",
    "# could either have the previous layers predict future layers, or could have all layers together predict \n",
    "# the accuracy improvement. I want to get the variables most of all, so how would I get those?\n",
    "# I need variations in those variables, and differences in accuracy as a result of those variables\n",
    "# I can start by randomly having variables and taking their accuracy improvement as above\n",
    "\n",
    "# maybe the model is input two sets of complete variables and it predicts which one is the best,\n",
    "# and what the accuracy of each is\n",
    "\n",
    "# also could compare against a base config, and estimate the accuracy of the unknown varset\n",
    "# send in set of layers and have it predict the nex\n",
    "# t layers value and the final accuracy\n",
    "\n",
    "#         should the end of each iters be net better? or do we care about after all layers do their iters\n",
    "#         the greedy approach could probably enable optimization and allow to compare accuracies at each step\n",
    "#         but it would not align as well with my original vision. if any step reduces the accuracy of the model\n",
    "#         you probably wouldnt want to do it in the future\n",
    "\n",
    "\n",
    "\n",
    "# inputs = []\n",
    "# targets = []\n",
    "\n",
    "# for i, layer in enumerate(schedules):\n",
    "#     if i % 2 != 1:\n",
    "#         input = []\n",
    "#         input.append(np.asarray([layer[\"idx\"], layer[\"iters\"], layer[\"lr\"]]))\n",
    "#         input.append(np.asarray([schedules[i+1][\"idx\"], schedules[i+1][\"iters\"], schedules[i+1][\"lr\"]]))\n",
    "#         targets.append(layer[\"acc\"])\n",
    "    \n",
    "# inputs = np.asarray(inputs)\n",
    "# targets = np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:26.723Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras import utils as np_utils\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, percentage = np.random.uniform(.1, .9), dataset = cifar10, augment_data = True):\n",
    "        self.percentage = percentage\n",
    "        \n",
    "        (self.X_train, self.y_train), (self.X_test, self.y_test) = dataset.load_data()\n",
    "\n",
    "        print(\"WARNING: number of categories is hardcoded, should make dynamic\")\n",
    "        self.y_train = np_utils.to_categorical(self.y_train, 10)\n",
    "        self.y_test = np_utils.to_categorical(self.y_test, 10)\n",
    "\n",
    "        if augment_data:\n",
    "            self.train_datagen = ImageDataGenerator(\n",
    "                  rotation_range=40,\n",
    "                  width_shift_range=0.2,\n",
    "                  height_shift_range=0.2,\n",
    "                  shear_range=0.2,\n",
    "                  zoom_range=0.2,\n",
    "                  horizontal_flip=True,\n",
    "                  fill_mode='nearest')\n",
    "        else:\n",
    "            self.train_datagen = ImageDataGenerator()\n",
    "\n",
    "        self.test_datagen = ImageDataGenerator()\n",
    "\n",
    "        self.X_train = self.X_train.astype('float32') / 255\n",
    "        self.X_test = self.X_test.astype('float32') / 255\n",
    "\n",
    "        X_train_mean = np.mean(self.X_train, axis = 0)\n",
    "        self.X_train -= X_train_mean\n",
    "        self.X_test -= X_train_mean\n",
    "\n",
    "        self.X_val, self.X_test, self.y_val, self.y_test = train_test_split(\n",
    "            self.X_test, self.y_test, test_size = 0.5)\n",
    "        \n",
    "        self.X_train_subset = self.X_train[:int(len(self.X_train) * self.percentage)]\n",
    "        self.y_train_subset = self.y_train[:int(len(self.y_train) * self.percentage)]\n",
    "        \n",
    "        self.X_val_subset = self.X_val[:int(len(self.X_val) * self.percentage)]\n",
    "        self.y_val_subset = self.y_val[:int(len(self.y_val) * self.percentage)]\n",
    "        \n",
    "        self.X_test_subset = self.X_test[:int(len(self.X_test) * self.percentage)]\n",
    "        self.y_test_subset = self.y_test[:int(len(self.y_test) * self.percentage)]\n",
    "        \n",
    "    def create_generators(self, batch_size = 32):\n",
    "        self.train_steps = int(len(self.X_train) * self.percentage) // batch_size\n",
    "        self.val_steps = int(len(self.X_val) * self.percentage) // batch_size\n",
    "        \n",
    "        train_generator = self.train_datagen.flow(\n",
    "                self.X_train_subset, self.y_train_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        validation_generator = self.test_datagen.flow(\n",
    "                self.X_val_subset, self.y_val_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        test_generator = self.test_datagen.flow(\n",
    "                self.X_test_subset, self.y_test_subset,\n",
    "                batch_size = batch_size)\n",
    "\n",
    "        return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:27.218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: number of categories is hardcoded, should make dynamic\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "def create_conv_net():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                            input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer = \"sgd\",\n",
    "         loss = \"categorical_crossentropy\",\n",
    "         metrics = [\"acc\"])\n",
    "    return model\n",
    "\n",
    "ds = Dataset(percentage=1,\n",
    "             augment_data=False)\n",
    "train_generator, validation_generator, test_generator = ds.create_generators(\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:27.744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Best\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, MaxPooling2D, Input, Conv2D, Flatten, AveragePooling2D, LSTM\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.core.debugger import set_trace\n",
    "from keras.optimizers import Adam, SGD\n",
    "from copy import deepcopy\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from copy import deepcopy, copy\n",
    "\n",
    "try:\n",
    "    print(\"Loading Best\")\n",
    "    net = load_model(\"best.h5\")\n",
    "    best_weights = net.get_weights()\n",
    "except:\n",
    "    print(\"Model not found, creating new model\")\n",
    "    net = create_conv_net()\n",
    "    \n",
    "for l in net.layers:\n",
    "    l.trainable = False\n",
    "    \n",
    "def compile_model(lr=1e-3):\n",
    "    net.compile(optimizer=SGD(lr),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"])\n",
    "    \n",
    "compile_model()\n",
    "\n",
    "def decision(probability):\n",
    "    return random.random() < probability\n",
    "\n",
    "def get_scaled_lr(lr):\n",
    "    min = 1e-6\n",
    "    max = 1e-1\n",
    "    return get_scaled(lr, min, max)\n",
    "\n",
    "def get_scaled(num, min, max):\n",
    "    mean = (max + min)/2\n",
    "\n",
    "    std = (((min - mean)**2 + (max - mean)**2)/2)**(1/2)\n",
    "\n",
    "    zero_mean = num - mean\n",
    "    scaled_num = zero_mean/std\n",
    "    \n",
    "    return scaled_num\n",
    "\n",
    "def unscale(num, min, max):\n",
    "    mean = (max + min)/2\n",
    "\n",
    "    std = (((min - mean)**2 + (max - mean)**2)/2)**(1/2)\n",
    "    \n",
    "    return (num*std) + mean\n",
    "\n",
    "def unscale_lr(lr):\n",
    "    return unscale(lr, 1e-5, 1e-2)\n",
    "\n",
    "# todo: would be nice to have a cached model instead of having to create a new one\n",
    "\n",
    "prev_acc = net.evaluate_generator(test_generator, steps = 100)[1]\n",
    "\n",
    "def train(schedule):\n",
    "    global net\n",
    "    global prev_acc\n",
    "    \n",
    "#     I given a random update, I should predict if it's good or bad\n",
    "# once it is sufficiently good, I can filter down the type of updates I check\n",
    "    \n",
    "    lr = unscale_lr(schedule[\"lr\"])\n",
    "    idx = schedule[\"idx\"]\n",
    "\n",
    "    net.layers[idx].trainable = True\n",
    "    compile_model(lr=lr)\n",
    "\n",
    "#     length = unscale_length(schedule[\"length\"])\n",
    "\n",
    "    net.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=48,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=36,\n",
    "        verbose=0)\n",
    "\n",
    "    net.layers[idx].trainable = False\n",
    "\n",
    "    acc = net.evaluate_generator(test_generator, steps = 50)[1]\n",
    "    \n",
    "    print(\"Acc: {}, Prev Acc: {}\".format(acc, prev_acc))\n",
    "    if  acc > prev_acc:\n",
    "        print(\"Saved New Best\")\n",
    "        net.save(\"best.h5\")\n",
    "        best_weights = net.get_weights()\n",
    "        prev_acc = copy(acc)\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            print(\"Reverted Model\")\n",
    "            net = net.load_weights(best_weights)\n",
    "        except:\n",
    "            pass\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:28.098Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index(location, random = False):\n",
    "    location += 1\n",
    "    location /= 2\n",
    "    \n",
    "    index = int(np.round(location * len(trainable_indices)))\n",
    "    \n",
    "#         index += np.random.choice([-1, 0, 0, 0, 0, 1])\n",
    "    index = min(index, len(trainable_indices) - 1)\n",
    "    index = max(index, 0)\n",
    "    return index\n",
    "\n",
    "def get_magnitude(index):\n",
    "    mean_param_count = net.count_params() / len(trainable_indices)\n",
    "    index_param_count = net.layers[index].count_params()\n",
    "    \n",
    "    mss = 0\n",
    "    \n",
    "    for i in range(len(trainable_indices)):\n",
    "        mss += (net.layers[trainable_indices[i]].count_params() - mean_param_count)**2\n",
    "        \n",
    "    std = mss**(1/2)\n",
    "    \n",
    "    ipc_zero = index_param_count - mean_param_count\n",
    "    scaled_ipc = ipc_zero/std\n",
    "    return scaled_ipc\n",
    "\n",
    "trainable_indices = []\n",
    "\n",
    "times_trained = {}\n",
    "\n",
    "for i, l in enumerate(net.layers):\n",
    "    if l.count_params() > 0:\n",
    "        trainable_indices.append(i)\n",
    "\n",
    "for i in range(len(trainable_indices)):\n",
    "    times_trained[i] = 0\n",
    "\n",
    "def transform_schedule(schedule):\n",
    "#     acc = train(schedule)\n",
    "#     transformed_schedule = np.asarray([acc, schedule[\"location\"], schedule[\"num_indices\"], \n",
    "#                                        schedule[\"times_trained\"], schedule[\"magnitude\"], schedule[\"lr\"]])\n",
    "    \n",
    "    transformed_schedule = np.asarray([schedule[\"lr\"], schedule[\"curr_acc\"],\n",
    "                                       schedule[\"location\"], schedule[\"magnitude\"]])\n",
    "    \n",
    "    transformed_schedule = transformed_schedule\n",
    "    \n",
    "    return transformed_schedule\n",
    "\n",
    "def make_schedule():\n",
    "    schedule = {}\n",
    "    \n",
    "    schedule[\"lr\"] = get_scaled_lr(np.random.uniform(1e-6, 1e-1))\n",
    "    schedule[\"curr_acc\"] = prev_acc\n",
    "    schedule[\"location\"] = np.random.uniform(-1, 1)\n",
    "    schedule[\"idx\"] = get_index(schedule[\"location\"])\n",
    "    schedule[\"magnitude\"] = get_magnitude(schedule[\"idx\"])\n",
    "    transformed_schedule = transform_schedule(schedule)\n",
    "    \n",
    "    return np.expand_dims(np.expand_dims(np.asarray(transformed_schedule), axis=0), axis=0), schedule\n",
    "\n",
    "def check_good_or_bad(schedule):\n",
    "    return np.array([[train(schedule)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:28.443Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def penalized_loss(noise):\n",
    "#     def loss(y_true, y_pred):\n",
    "#         return K.mean(K.square(y_pred - y_true) - K.square(y_true - noise), axis=-1)\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# input1 = Input(batch_shape=(batch_size, timesteps, features))\n",
    "# lstm =  LSTM(features, stateful=True, return_sequences=True)(input1)\n",
    "# output1 = TimeDistributed(Dense(features, activation='sigmoid'))(lstm)\n",
    "# output2 = TimeDistributed(Dense(features, activation='sigmoid'))(lstm)\n",
    "# model = Model(input=[input1], output=[output1, output2])\n",
    "# model.compile(loss=[penalized_loss(noise=output2), penalized_loss(noise=output1)], optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:28.954Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example input:\n",
    "# network architecture?\n",
    "# current learning rate magnitude\n",
    "# age of layer\n",
    "# location of layer\n",
    "# loss can be auxiliary\n",
    "# inputs start random and the LSTM will be reinforced from good changes\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "# could either do one layer update at a time or the whole model at once\n",
    "# one layer at a time might be more overhead, but might optimize more\n",
    "# whole model might train easier too\n",
    "\n",
    "#might need to make a custom layer where I construct the model and return the accuracy of it, and\n",
    "# use that as the loss against perfect acc\n",
    "\n",
    "# how could I split the lstm\n",
    "\n",
    "# have an lstm that produces a schedule given a previous schedule\n",
    "\n",
    "def sameness_loss(y_true, y_pred):\n",
    "    return K.mean(K.pow(y_pred - y_true, -2), axis=-1)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    if y_pred.shape[1].value == 2:\n",
    "        return sameness_loss(y_true, y_pred)\n",
    "    else:\n",
    "        return mean_squared_error(y_true,y_pred)\n",
    "\n",
    "def create_LSTM():\n",
    "#     input is a random update\n",
    "    input = Input(shape = (1, 4,))\n",
    "    \n",
    "    x = LSTM(256, dropout = 0.5, recurrent_dropout = 0.5, return_sequences = True, activation = \"relu\")(input)\n",
    "    x = LSTM(256, dropout = 0.5, recurrent_dropout = 0.5, return_sequences = True, activation = \"relu\")(x)\n",
    "    x = LSTM(256, dropout = 0.5, recurrent_dropout = 0.5, activation = \"relu\")(x)\n",
    "#     output is how likely this update is good or bad, or could do each individual update?\n",
    "    good_or_bad = Dense(1, activation = \"sigmoid\")(x)\n",
    "    \n",
    "#     need two losses: one that penalizes the mse between predicted_acc and actual_acc\n",
    "#     predictions = Dense(int(len(trainable_indices)*2))(x)\n",
    "\n",
    "# idea: have the model predict a percentage of the model, and the program selects the closest trainable\n",
    "# index\n",
    "\n",
    "# need to tie together predicting accuracy and proposing a new schedule\n",
    "    \n",
    "    model = Model(inputs=input, \n",
    "                  outputs=good_or_bad)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr = 1e-3), loss=\"binary_crossentropy\", metrics=[\"mae\"])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "#     idea: have an aux loss which looks at predicted accuracy for the predicted vars and the loss is how\n",
    "# far that is from a desired acc (.9)\n",
    "\n",
    "# try:\n",
    "#     lstm = load_model(\"best_lstm.h5\")\n",
    "# except:\n",
    "lstm = create_LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm.compile(optimizer=Adam(lr = 8e-4), loss=\"binary_crossentropy\", metrics=[\"mae\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = create_conv_net()\n",
    "inputs = []\n",
    "targets = []\n",
    "num_good = 0\n",
    "num_bad = 0\n",
    "inputs_targets = []\n",
    "\n",
    "prev_acc = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.1183206106870229, Prev Acc: 0.1\n",
      "Saved New Best\n",
      "Acc: 0.1275, Prev Acc: 0.1183206106870229\n",
      "Saved New Best\n",
      "Acc: 0.1313613231552163, Prev Acc: 0.1275\n",
      "Saved New Best\n",
      "Acc: 0.16221374045801526, Prev Acc: 0.1313613231552163\n",
      "Saved New Best\n",
      "Acc: 0.1678125, Prev Acc: 0.16221374045801526\n",
      "Saved New Best\n",
      "Acc: 0.1696875, Prev Acc: 0.1678125\n",
      "Saved New Best\n",
      "Acc: 0.17239185750636132, Prev Acc: 0.1696875\n",
      "Saved New Best\n",
      "Acc: 0.178117048346056, Prev Acc: 0.17239185750636132\n",
      "Saved New Best\n",
      "Acc: 0.1684375, Prev Acc: 0.178117048346056\n",
      "Reverted Model\n",
      "Acc: 0.1753125, Prev Acc: 0.178117048346056\n",
      "Reverted Model\n",
      "Acc: 0.16762086513994912, Prev Acc: 0.178117048346056\n",
      "Reverted Model\n",
      "Acc: 0.1806615776081425, Prev Acc: 0.178117048346056\n",
      "Saved New Best\n",
      "Acc: 0.1903125, Prev Acc: 0.1806615776081425\n",
      "Saved New Best\n",
      "Acc: 0.1990625, Prev Acc: 0.1903125\n",
      "Saved New Best\n",
      "Acc: 0.191793893129771, Prev Acc: 0.1990625\n",
      "Reverted Model\n",
      "Acc: 0.19083969465648856, Prev Acc: 0.1990625\n",
      "Reverted Model\n",
      "Acc: 0.195625, Prev Acc: 0.1990625\n",
      "Reverted Model\n",
      "Acc: 0.20125, Prev Acc: 0.1990625\n",
      "Saved New Best\n",
      "Acc: 0.21596692111959287, Prev Acc: 0.20125\n",
      "Saved New Best\n",
      "Acc: 0.21914758269720103, Prev Acc: 0.21596692111959287\n",
      "Saved New Best\n",
      "Acc: 0.22375, Prev Acc: 0.21914758269720103\n",
      "Saved New Best\n",
      "Acc: 0.2284375, Prev Acc: 0.22375\n",
      "Saved New Best\n",
      "Acc: 0.2299618320610687, Prev Acc: 0.2284375\n",
      "Saved New Best\n",
      "Acc: 0.2340966921119593, Prev Acc: 0.2299618320610687\n",
      "Saved New Best\n",
      "Acc: 0.226875, Prev Acc: 0.2340966921119593\n",
      "Reverted Model\n",
      "Acc: 0.23625, Prev Acc: 0.2340966921119593\n",
      "Saved New Best\n",
      "Acc: 0.21692111959287533, Prev Acc: 0.23625\n",
      "Reverted Model\n",
      "Acc: 0.22073791348600508, Prev Acc: 0.23625\n",
      "Reverted Model\n",
      "Acc: 0.225, Prev Acc: 0.23625\n",
      "Reverted Model\n",
      "Acc: 0.23027989821882952, Prev Acc: 0.23625\n",
      "Reverted Model\n",
      "Acc: 0.22232824427480916, Prev Acc: 0.23625\n",
      "Reverted Model\n",
      "Acc: 0.2407760814249364, Prev Acc: 0.23625\n",
      "Saved New Best\n",
      "Acc: 0.23125, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.23027989821882952, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.2366412213740458, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.23123409669211195, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.2165625, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.2344147582697201, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.23791348600508905, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.22678117048346055, Prev Acc: 0.2407760814249364\n",
      "Reverted Model\n",
      "Acc: 0.2409375, Prev Acc: 0.2407760814249364\n",
      "Saved New Best\n",
      "Acc: 0.24045801526717558, Prev Acc: 0.2409375\n",
      "Reverted Model\n",
      "Acc: 0.23473282442748092, Prev Acc: 0.2409375\n",
      "Reverted Model\n",
      "Acc: 0.24459287531806614, Prev Acc: 0.2409375\n",
      "Saved New Best\n",
      "Acc: 0.244375, Prev Acc: 0.24459287531806614\n",
      "Reverted Model\n",
      "Acc: 0.2410941475826972, Prev Acc: 0.24459287531806614\n",
      "Reverted Model\n",
      "Acc: 0.2477735368956743, Prev Acc: 0.24459287531806614\n",
      "Saved New Best\n",
      "Acc: 0.23791348600508905, Prev Acc: 0.2477735368956743\n",
      "Reverted Model\n",
      "Acc: 0.2384375, Prev Acc: 0.2477735368956743\n",
      "Reverted Model\n",
      "Acc: 0.24872773536895673, Prev Acc: 0.2477735368956743\n",
      "Saved New Best\n",
      "Acc: 0.2407760814249364, Prev Acc: 0.24872773536895673\n",
      "Reverted Model\n",
      "Acc: 0.24395674300254452, Prev Acc: 0.24872773536895673\n",
      "Reverted Model\n",
      "Acc: 0.2509375, Prev Acc: 0.24872773536895673\n",
      "Saved New Best\n",
      "Acc: 0.24427480916030533, Prev Acc: 0.2509375\n",
      "Reverted Model\n",
      "Acc: 0.24904580152671757, Prev Acc: 0.2509375\n",
      "Reverted Model\n",
      "Acc: 0.25699745547073793, Prev Acc: 0.2509375\n",
      "Saved New Best\n",
      "Acc: 0.2425, Prev Acc: 0.25699745547073793\n",
      "Reverted Model\n",
      "Acc: 0.24840966921119592, Prev Acc: 0.25699745547073793\n",
      "Reverted Model\n",
      "Acc: 0.2474554707379135, Prev Acc: 0.25699745547073793\n",
      "Reverted Model\n",
      "Acc: 0.2559375, Prev Acc: 0.25699745547073793\n",
      "Reverted Model\n",
      "Acc: 0.2578125, Prev Acc: 0.25699745547073793\n",
      "Saved New Best\n",
      "Acc: 0.25190839694656486, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.25318066157760816, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.2540625, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.2459375, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.2458651399491094, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.2477735368956743, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.2415625, Prev Acc: 0.2578125\n",
      "Reverted Model\n",
      "Acc: 0.265, Prev Acc: 0.2578125\n",
      "Saved New Best\n",
      "Acc: 0.2589058524173028, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.25190839694656486, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.2553125, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.2578125, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.26049618320610685, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.263676844783715, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.2525, Prev Acc: 0.265\n",
      "Reverted Model\n",
      "Acc: 0.2721875, Prev Acc: 0.265\n",
      "Saved New Best\n",
      "Acc: 0.26494910941475824, Prev Acc: 0.2721875\n",
      "Reverted Model\n",
      "Acc: 0.25763358778625955, Prev Acc: 0.2721875\n",
      "Reverted Model\n",
      "Acc: 0.2690625, Prev Acc: 0.2721875\n",
      "Reverted Model\n",
      "Acc: 0.2603125, Prev Acc: 0.2721875\n",
      "Reverted Model\n",
      "Acc: 0.2865776081424936, Prev Acc: 0.2721875\n",
      "Saved New Best\n",
      "Acc: 0.26622137404580154, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.2740625, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.26875, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.280852417302799, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.2786259541984733, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.2828125, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.273125, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.27735368956743, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.2862595419847328, Prev Acc: 0.2865776081424936\n",
      "Reverted Model\n",
      "Acc: 0.2928125, Prev Acc: 0.2865776081424936\n",
      "Saved New Best\n",
      "Acc: 0.2925, Prev Acc: 0.2928125\n",
      "Reverted Model\n",
      "Acc: 0.29389312977099236, Prev Acc: 0.2928125\n",
      "Saved New Best\n",
      "Acc: 0.2919847328244275, Prev Acc: 0.29389312977099236\n",
      "Reverted Model\n",
      "Acc: 0.2871875, Prev Acc: 0.29389312977099236\n",
      "Reverted Model\n",
      "Acc: 0.291875, Prev Acc: 0.29389312977099236\n",
      "Reverted Model\n",
      "Acc: 0.28053435114503816, Prev Acc: 0.29389312977099236\n",
      "Reverted Model\n",
      "Acc: 0.2856234096692112, Prev Acc: 0.29389312977099236\n",
      "Reverted Model\n",
      "Acc: 0.2971875, Prev Acc: 0.29389312977099236\n",
      "Saved New Best\n",
      "Acc: 0.296875, Prev Acc: 0.2971875\n",
      "Reverted Model\n",
      "Acc: 0.2973918575063613, Prev Acc: 0.2971875\n",
      "Saved New Best\n",
      "Acc: 0.2913486005089059, Prev Acc: 0.2973918575063613\n",
      "Reverted Model\n",
      "Acc: 0.30125, Prev Acc: 0.2973918575063613\n",
      "Saved New Best\n",
      "Acc: 0.300625, Prev Acc: 0.30125\n",
      "Reverted Model\n",
      "Acc: 0.30693384223918574, Prev Acc: 0.30125\n",
      "Saved New Best\n",
      "Acc: 0.30852417302798985, Prev Acc: 0.30693384223918574\n",
      "Saved New Best\n",
      "Acc: 0.301875, Prev Acc: 0.30852417302798985\n",
      "Reverted Model\n",
      "Acc: 0.31375, Prev Acc: 0.30852417302798985\n",
      "Saved New Best\n",
      "Acc: 0.30916030534351147, Prev Acc: 0.31375\n",
      "Reverted Model\n",
      "Acc: 0.30407124681933845, Prev Acc: 0.31375\n",
      "Reverted Model\n",
      "Acc: 0.3178125, Prev Acc: 0.31375\n",
      "Saved New Best\n",
      "Acc: 0.316875, Prev Acc: 0.3178125\n",
      "Reverted Model\n",
      "Acc: 0.31138676844783714, Prev Acc: 0.3178125\n",
      "Reverted Model\n",
      "Acc: 0.3104325699745547, Prev Acc: 0.3178125\n",
      "Reverted Model\n",
      "Acc: 0.3165625, Prev Acc: 0.3178125\n",
      "Reverted Model\n",
      "Acc: 0.3325, Prev Acc: 0.3178125\n",
      "Saved New Best\n",
      "Acc: 0.31583969465648853, Prev Acc: 0.3325\n",
      "Reverted Model\n",
      "Acc: 0.3212468193384224, Prev Acc: 0.3325\n",
      "Reverted Model\n",
      "Acc: 0.325, Prev Acc: 0.3325\n",
      "Reverted Model\n",
      "Acc: 0.3340625, Prev Acc: 0.3325\n",
      "Saved New Best\n",
      "Acc: 0.3256997455470738, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Acc: 0.3199745547073791, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Acc: 0.32, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Acc: 0.31875, Prev Acc: 0.3340625\n",
      "Reverted Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0a96ceed1694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgood_or_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_good_or_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgood_or_bad\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_bad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-497099c0db4d>\u001b[0m in \u001b[0;36mcheck_good_or_bad\u001b[0;34m(schedule)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_good_or_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-4721f4b31351>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(schedule)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         verbose=0)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input, schedule = make_schedule()\n",
    "    good_or_bad = check_good_or_bad(schedule)\n",
    "    \n",
    "    if good_or_bad == 0 and num_bad < 50:\n",
    "        inputs_targets.append((input, good_or_bad))\n",
    "    elif good_or_bad == 1 and num_good < 50:\n",
    "        inputs_targets.append((input, good_or_bad))\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import pickle\n",
    "\n",
    "shuffle(inputs_targets)\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for it in inputs_targets:\n",
    "    inputs.append(it[0])\n",
    "    targets.append(it[1])\n",
    "    \n",
    "# pickle.dump(inputs, open(\"inputs.p\", \"wb\"))\n",
    "# pickle.dump(targets, open(\"targets.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-08T19:35:29.938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.3212468193384224, Prev Acc: 0.33125\n",
      "Reverted Model\n",
      "Predicted: 0.0, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "8s - loss: 0.0000e+00 - mean_absolute_error: 1.5048e-22\n",
      "Acc: 0.32665394402035625, Prev Acc: 0.33125\n",
      "Reverted Model\n",
      "Predicted: 0.0, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.4525e-38 - mean_absolute_error: 1.2052e-19\n",
      "Acc: 0.3290625, Prev Acc: 0.33125\n",
      "Reverted Model\n",
      "Predicted: 5.0873850909738394e-08, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 3.0622e-29\n",
      "Acc: 0.32665394402035625, Prev Acc: 0.33125\n",
      "Reverted Model\n",
      "Predicted: 2.092201828451934e-10, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 3.1328e-13 - mean_absolute_error: 5.5972e-07\n",
      "Acc: 0.3244274809160305, Prev Acc: 0.33125\n",
      "Reverted Model\n",
      "Predicted: 2.850833284717691e-11, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 1.0027e-24\n",
      "Acc: 0.3336513994910941, Prev Acc: 0.33125\n",
      "Saved New Best\n",
      "Predicted: 1.713376219113498e-18, Actual: [[1]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.0000 - mean_absolute_error: 1.0000\n",
      "Acc: 0.314375, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 1.444747945269987e-23, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 8.9385e-28\n",
      "Acc: 0.3336513994910941, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 1.1187648030208663e-10, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.8665e-17 - mean_absolute_error: 4.3202e-09\n",
      "Acc: 0.31329516539440205, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 3.0895911390085442e-18, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 3.8202e-22\n",
      "Acc: 0.3284375, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 1.3833612922032777e-15, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 5.1448e-34 - mean_absolute_error: 2.2682e-17\n",
      "Acc: 0.3278125, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 3.4807934312652833e-09, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 3.4611e-14 - mean_absolute_error: 1.8604e-07\n",
      "Acc: 0.32156488549618323, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 1.69120999083976e-22, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 1.1648e-31\n",
      "Acc: 0.32220101781170485, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 1.5551263057226293e-19, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 2.5204e-33 - mean_absolute_error: 5.0203e-17\n",
      "Acc: 0.3193384223918575, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 5.6022191751586824e-24, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 4.3191e-34 - mean_absolute_error: 2.0782e-17\n",
      "Acc: 0.3234375, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 8.915331051184694e-08, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 4.5814e-12 - mean_absolute_error: 2.1404e-06\n",
      "Acc: 0.32474554707379133, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 2.9197325659005416e-36, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.5876e-29 - mean_absolute_error: 3.9844e-15\n",
      "Acc: 0.33078880407124683, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 0.0, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n",
      "Acc: 0.32188295165394404, Prev Acc: 0.3336513994910941\n",
      "Reverted Model\n",
      "Predicted: 0.0, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n",
      "Acc: 0.3340625, Prev Acc: 0.3336513994910941\n",
      "Saved New Best\n",
      "Predicted: 1.0766012098367547e-18, Actual: [[1]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.0000 - mean_absolute_error: 1.0000\n",
      "Acc: 0.32283715012722647, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Predicted: 2.1093633222335484e-06, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.6451e-20 - mean_absolute_error: 1.2826e-10\n",
      "Acc: 0.32697201017811706, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Predicted: 3.677179077253578e-32, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n",
      "Acc: 0.32, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Predicted: 5.986605778116356e-29, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n",
      "Acc: 0.328125, Prev Acc: 0.3340625\n",
      "Reverted Model\n",
      "Predicted: 2.68518817360806e-23, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 3.5485e-32\n",
      "Acc: 0.3368320610687023, Prev Acc: 0.3340625\n",
      "Saved New Best\n",
      "Predicted: 1.518903007160776e-29, Actual: [[1]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.0000 - mean_absolute_error: 1.0000\n",
      "Acc: 0.31202290076335876, Prev Acc: 0.3368320610687023\n",
      "Reverted Model\n",
      "Predicted: 4.696307769336272e-06, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 4.2298e-14 - mean_absolute_error: 2.0566e-07\n",
      "Acc: 0.318125, Prev Acc: 0.3368320610687023\n",
      "Reverted Model\n",
      "Predicted: 2.5173867305592395e-23, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n",
      "Acc: 0.3334375, Prev Acc: 0.3368320610687023\n",
      "Reverted Model\n",
      "Predicted: 1.3172867738830973e-06, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.1275e-32 - mean_absolute_error: 1.0618e-16\n",
      "Acc: 0.33142493638676845, Prev Acc: 0.3368320610687023\n",
      "Reverted Model\n",
      "Predicted: 4.1613275243435055e-06, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 1.5339e-17 - mean_absolute_error: 3.9165e-09\n",
      "Acc: 0.3279262086513995, Prev Acc: 0.3368320610687023\n",
      "Reverted Model\n",
      "Predicted: 2.2898419323726828e-24, Actual: [[0]]\n",
      "Epoch 1/1\n",
      "0s - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-16b1652dc70f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_or_bad_pred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mgood_or_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_good_or_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted: {}, Actual: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_or_bad_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_or_bad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_or_bad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-497099c0db4d>\u001b[0m in \u001b[0;36mcheck_good_or_bad\u001b[0;34m(schedule)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_good_or_bad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-4721f4b31351>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(schedule)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         verbose=0)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1922\u001b[0m                                 \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m                                 pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1925\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_q_size, workers, pickle_safe)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                                      \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m                                      str(generator_output))\n\u001b[0;32m-> 2021\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_cycles = 10000\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    input, schedule = make_schedule()\n",
    "    good_or_bad_pred = lstm.predict(input)[0][0]\n",
    "    \n",
    "    if decision(good_or_bad_pred + .01):\n",
    "        good_or_bad = check_good_or_bad(schedule)\n",
    "        print(\"Predicted: {}, Actual: {}\".format(good_or_bad_pred, good_or_bad))\n",
    "        lstm.fit(input, good_or_bad, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lstm.save(\"best_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T19:21:33.923045Z",
     "start_time": "2017-12-08T19:20:49.960Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maybe external output which maps to the accuracy of the last model\n",
    "# or have the lstm predict the accuracy of the last one and the between that\n",
    "\n",
    "# i want an lstm gan which is fed it's previous predicted pieces(starts being random) and predicts the accuracy\n",
    "# of it's inputs\n",
    "\n",
    "\n",
    "\n",
    "# def randomize_lr(lr):\n",
    "#     if decision(.7):\n",
    "#         return lr\n",
    "#     else: \n",
    "#         return get_scaled_lr(np.random.uniform(5e-5, 5e-1))\n",
    "\n",
    "# def randomize_location(loc):\n",
    "#     if decision(.7):\n",
    "#         return loc\n",
    "#     else:\n",
    "#         return np.random.uniform(-1, 1)\n",
    "\n",
    "\n",
    "        \n",
    "# for i in range(len(trainable_indices)):\n",
    "#     print(\"Cycle %d\" % (i))\n",
    "\n",
    "    \n",
    "#     good_or_bad_pred = prediction[0]\n",
    "# #     next_schedule[0][0] = np.random.uniform(-1, 1)\n",
    "# #     next_schedule[0][1] = np.random.uniform(-1, 1)\n",
    "\n",
    "#     schedules, acc = create_schedules(trainable, lr)\n",
    "\n",
    "# #     schedule = {}\n",
    "# #     schedule[\"location\"] = location\n",
    "# #     schedule[\"idx\"] = get_index(schedule[\"location\"])\n",
    "# #     schedule[\"trainable\"] = trainable\n",
    "#     #     schedule[\"num_indices\"] = len(trainable_indices)\n",
    "#     #     schedule[\"times_trained\"] = times_trained[schedule[\"idx\"]]\n",
    "# #     schedule[\"magnitude\"] = get_magnitude(schedule[\"idx\"])\n",
    "#     #     + (np.random.uniform(-1, 1) / 1e3)\n",
    "# #     schedule[\"lr\"] = lr\n",
    "#     #     + (np.random.uniform(-1, 1) * 1e-4\n",
    "\n",
    "#     print(schedules, predicted_acc)\n",
    "    \n",
    "#     lstm_inputs = schedules\n",
    "\n",
    "#     lstm_targets = []\n",
    "#     lstm_targets.append(np.zeros((1, 5)))\n",
    "#     lstm_targets.append(np.zeros((1, 5)))\n",
    "#     lstm_targets.append(predicted_acc)\n",
    "#     lstm_targets.append(np.array([[.9]]))\n",
    "    \n",
    "#     lstm.fit(lstm_inputs, lstm_targets)\n",
    "    \n",
    "# # diff between prediction accuracy and actual\n",
    "\n",
    "\n",
    "\n",
    "# # lstm_inputs = np.asarray([np.expand_dims(lstm.predict(lstm_inputs, lstm_target), axis=0)])\n",
    "\n",
    "# res = lstm.predict(input, target[\"vars\"], target[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T18:58:30.098478Z",
     "start_time": "2017-12-08T18:58:30.089693Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# issue: the output for the models is just continually going up. this is probably because it predicts that the\n",
    "# accuracy will slowly rise. the output needs a direct loss or it will not be able to train properly\n",
    "# the issue is that without a loss which will propagate to that part for that purpose, it will not learn as\n",
    "# desired. The issue also is that we cannot provide good examples, we want the network to learn it.\n",
    "# Maybe changing the accuracy to an aux loss and having the main loss be . . . . . . .\n",
    "\n",
    "# need a loss that will penalize the predicted numbers for not increasing the accuracy\n",
    "# the issue is that predicting accuracy just makes the model learn to predict the pattern of how the accuracy\n",
    "# generally increases, rather than any deeper meaning. \n",
    "\n",
    "# want to produce a location and a learning rate, see how much they improved the accuracy, and penalize the \n",
    "# difference between that and an ideal rate on improvement (5%)\n",
    "\n",
    "# right now it is just predicting that the accuracy will slowly increase\n",
    "# what we want is to have it be heavily penalized for not improving faster, and be encouraged to try new things\n",
    "# maybe we don't care what the predicted accuracy is? but then how will we connect the layer to the loss\n",
    "\n",
    "# the loss right now is just not good enough to work\n",
    "# An issue could be that I'm using single sequences rather than the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T18:00:39.937007Z",
     "start_time": "2017-12-08T18:00:38.170Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for input in inputs:\n",
    "#     want lstm's loss to be based on changing variables to improve accuracy\n",
    "# so need to input negative examples and good examples, or have the lstm randomly \n",
    "# choose\n",
    "    predictions.append(lstm.evaluate(input, target))\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "#     0 is iters, 1 is lr, 2 is trainable\n",
    "    layers[i].age += predictions[i][0]\n",
    "    layers[i][\"iters\"] = predictions[i][0]\n",
    "    layers[i][\"lr\"] = predictions[i][1]\n",
    "    layers[i][\"trainable\"] = predictions[i][2]\n",
    "    conv_model.layers[layer[\"name\"]].trainable = predictions[i][2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T18:00:39.938345Z",
     "start_time": "2017-12-08T18:00:39.194Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, clone_model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, MaxPooling2D, Input, Conv2D, Flatten, AveragePooling2D\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.core.debugger import set_trace\n",
    "from keras.optimizers import Adam\n",
    "from copy import deepcopy\n",
    "\n",
    "ds = Dataset(percentage = 1,\n",
    "             augment_data = False)\n",
    "train_generator, validation_generator, test_generator = ds.create_generators(batch_size = 64);\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, \n",
    "                 activation = 'relu', \n",
    "                 input_shape = (32, 32, 3)))\n",
    "model.add(Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(AveragePooling2D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "def train():\n",
    "    history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = ds.train_steps // 4,\n",
    "    epochs = 20,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = ds.val_steps // 4,\n",
    "    verbose = 1)   \n",
    "\n",
    "try:\n",
    "    def train_input():\n",
    "        for i, layer in enumerate(model.layers):\n",
    "        if i == 0:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        model.compile(optimizer = Adam(1e-4),\n",
    "         loss = \"categorical_crossentropy\",\n",
    "         metrics = [\"acc\"])\n",
    "        train()\n",
    "except KeyboardInterrupt as e:\n",
    "    pass\n",
    "  \n",
    "try:\n",
    "    def train_output():\n",
    "        for i, layer in enumerate(model.layers):\n",
    "        if i == (len(model.layers)-1):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "        model.compile(optimizer = Adam(1e-4),\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = [\"acc\"])\n",
    "        train()\n",
    "except KeyboardInterrupt as e:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    def train_conv2d3x3():\n",
    "        for i, layer in enumerate(model.layers):\n",
    "        if \"conv2d\" in name:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "        model.compile(optimizer = Adam(1e-4),\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = [\"acc\"])\n",
    "        train()\n",
    "except KeyboardInterrupt as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T21:46:11.173219Z",
     "start_time": "2017-11-21T21:37:56.105233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer made trainable <keras.layers.convolutional.Conv2D object at 0x7f803ac2a400>\n",
      "layer made trainable <keras.layers.convolutional.Conv2D object at 0x7f803a869c18>\n",
      "layer made trainable <keras.layers.convolutional.Conv2D object at 0x7f803a869d30>\n",
      "layer made trainable <keras.layers.convolutional.Conv2D object at 0x7f803a869dd8>\n",
      "layer made trainable <keras.layers.core.Dense object at 0x7f803a7bcd68>\n",
      "Epoch 1/20\n",
      "195/195 [==============================] - 45s - loss: 1.3220 - acc: 0.5348 - val_loss: 1.2841 - val_acc: 0.5452\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 43s - loss: 1.2628 - acc: 0.5641 - val_loss: 1.3674 - val_acc: 0.5206\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 41s - loss: 1.2714 - acc: 0.5538 - val_loss: 1.3651 - val_acc: 0.5198\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 42s - loss: 1.2846 - acc: 0.5445 - val_loss: 1.3259 - val_acc: 0.5387\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 44s - loss: 1.2809 - acc: 0.5532 - val_loss: 1.3310 - val_acc: 0.5329\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 44s - loss: 1.2859 - acc: 0.5500 - val_loss: 1.3700 - val_acc: 0.5086\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 43s - loss: 1.2622 - acc: 0.5584 - val_loss: 1.3107 - val_acc: 0.5288\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 44s - loss: 1.2758 - acc: 0.5545 - val_loss: 1.3424 - val_acc: 0.5362\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 42s - loss: 1.2748 - acc: 0.5524 - val_loss: 1.3700 - val_acc: 0.5115\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 45s - loss: 1.2951 - acc: 0.5455 - val_loss: 1.3235 - val_acc: 0.5164\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 43s - loss: 1.2738 - acc: 0.5530 - val_loss: 1.2949 - val_acc: 0.5491\n",
      "Epoch 12/20\n",
      " 73/195 [==========>...................] - ETA: 25s - loss: 1.2741 - acc: 0.5524"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-96ea6b8603af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_steps\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     verbose = 1)\n\u001b[0m",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.trainable and i != 0 and i != (len(model.layers)-1):\n",
    "        name = \"\".join(layer.name.split(\"_\")[:-1])\n",
    "        if \"conv2d\" in name:\n",
    "            layer.trainable = False\n",
    "            print(\"layer made untrainable\", layer)\n",
    "    else:\n",
    "        layer.trainable = True\n",
    "        print(\"layer made trainable\", layer)   \n",
    "\n",
    "model.compile(optimizer = Adam(5e-3),\n",
    "     loss = \"categorical_crossentropy\",\n",
    "     metrics = [\"acc\"])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = ds.train_steps // 4,\n",
    "    epochs = 20,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = ds.val_steps // 4,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T21:48:05.559965Z",
     "start_time": "2017-11-21T21:48:05.389418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists, join\n",
    "\n",
    "weights = []\n",
    "output_weights = None\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    name = \"\".join(layer.name.split(\"_\")[:-1])\n",
    "    if not exists(join(\"parameters\", name)):\n",
    "        mkdir(join(\"parameters\", name))\n",
    "    input_shape_str = \"_\".join(map(str, layer.input_shape[1:]))\n",
    "    if \"conv\" in name.lower():\n",
    "        if i == 0:\n",
    "            input_weights = layer.get_weights()\n",
    "        else:\n",
    "            weights.append(layer.get_weights())\n",
    "    elif \"dense\" in name.lower():\n",
    "        output_weights = layer.get_weights()\n",
    "#         weights_filename = save_parameters(layer, name, input_shape_str, \"weights\", 0)\n",
    "#         biases_filename = save_parameters(layer, name, input_shape_str, \"biases\", 0)\n",
    "print(len(weights))\n",
    "\n",
    "def save_weights(input = False, output = False):\n",
    "    if input:\n",
    "        np.save(\"input_weights_conv2d3x3.npy\", input_weights)\n",
    "        \n",
    "    current_weight = deepcopy(weights[0][0])\n",
    "    current_bias = deepcopy(weights[0][1])\n",
    "    for i in range(len(weights[1:]) - 1):\n",
    "        if i == 0:\n",
    "            weight_difference = current_weight - weights[i+1][0]\n",
    "            bias_difference = current_bias - weights[i+1][1]\n",
    "        else:\n",
    "            weight_difference = (weight_difference + current_weight - weights[i+1][0]) / 2\n",
    "            bias_difference = (bias_difference + current_bias - weights[i+1][1]) / 2\n",
    "        current_weight = deepcopy(weights[i+1][0])\n",
    "        current_bias = deepcopy(weights[i+1][1])\n",
    "    np.save(\"starting_params_conv2d3x3.npy\", weights[0])\n",
    "    np.save(\"weight_difference_conv2d3x3.npy\", weight_difference)\n",
    "    np.save(\"bias_difference_conv2d3x3.npy\", bias_difference)\n",
    "    if output:\n",
    "        np.save(\"output_weights|2048_10.npy\", output_weights)\n",
    "        \n",
    "save_weights(input = True, output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_parameters(layer, name, input_shape_str, param_type, motif_id):\n",
    "    if param_type is \"weights\":\n",
    "        params = layer.get_weights()[0]\n",
    "    else:\n",
    "        params = layer.get_weights()[1]\n",
    "    params_filename = join(\"parameters\", str(motif_id) + \"~\" + name, param_type + \"_\" + input_shape_str + \"-0.npy\")\n",
    "    path = Path(params_filename)\n",
    "    \n",
    "    i = 1\n",
    "    while True:\n",
    "        if path.is_file():\n",
    "            params_filename = params_filename.split(\"-\")[0] + \"-%d\" % (i) + \".npy\"\n",
    "            path = Path(params_filename)\n",
    "        else:\n",
    "            np.save(params_filename, params)\n",
    "            break\n",
    "        i += 1\n",
    "    return params_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T18:05:46.680891Z",
     "start_time": "2017-11-21T18:02:44.410826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Tensor(\"conv2d_21/add:0\", shape=(3, 3, 3, 32), dtype=float32)\n",
      "13 Tensor(\"conv2d_22/add:0\", shape=(3, 3, 3, 32), dtype=float32)\n",
      "Epoch 1/20\n",
      "156/156 [==============================] - 9s - loss: 7.9681 - acc: 0.1008 - val_loss: 7.7773 - val_acc: 0.1062\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 9s - loss: 8.4228 - acc: 0.0940 - val_loss: 7.8321 - val_acc: 0.1325\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 8s - loss: 8.3699 - acc: 0.1088 - val_loss: 9.0893 - val_acc: 0.1175\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 8s - loss: 8.0127 - acc: 0.1216 - val_loss: 7.8835 - val_acc: 0.1432\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 8s - loss: 7.9720 - acc: 0.1136 - val_loss: 9.0958 - val_acc: 0.1474\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 8s - loss: 7.9408 - acc: 0.1110 - val_loss: 7.8057 - val_acc: 0.1453\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 8s - loss: 7.9515 - acc: 0.1130 - val_loss: 7.3549 - val_acc: 0.1346\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 8s - loss: 8.0813 - acc: 0.0956 - val_loss: 7.6937 - val_acc: 0.0919\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 8s - loss: 8.0460 - acc: 0.0913 - val_loss: 8.4222 - val_acc: 0.1004\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 8s - loss: 7.9290 - acc: 0.0911 - val_loss: 8.4268 - val_acc: 0.0983\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 9s - loss: 7.9657 - acc: 0.0917 - val_loss: 8.6627 - val_acc: 0.1004\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 8s - loss: 7.8799 - acc: 0.0926 - val_loss: 8.4416 - val_acc: 0.1090\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 8s - loss: 8.0050 - acc: 0.0915 - val_loss: 8.1815 - val_acc: 0.0919\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 8s - loss: 8.0586 - acc: 0.0917 - val_loss: 8.2147 - val_acc: 0.1068\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 8s - loss: 8.0051 - acc: 0.0940 - val_loss: 8.6580 - val_acc: 0.1090\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 9s - loss: 7.8463 - acc: 0.1008 - val_loss: 7.9429 - val_acc: 0.0983\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 8s - loss: 7.9120 - acc: 0.0887 - val_loss: 7.9413 - val_acc: 0.1042\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 8s - loss: 8.3352 - acc: 0.0940 - val_loss: 8.8644 - val_acc: 0.1004\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 8s - loss: 8.1836 - acc: 0.0897 - val_loss: 8.7224 - val_acc: 0.1047\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 8s - loss: 8.1990 - acc: 0.0968 - val_loss: 8.5533 - val_acc: 0.1111\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'parameters/14~conv2d/weights_32_32_3-0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3abfa610462f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0minput_shape_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mweights_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mbiases_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"biases\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-3abfa610462f>\u001b[0m in \u001b[0;36msave_parameters\u001b[0;34m(layer, name, input_shape_str, param_type, motif_id)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/miniconda3/envs/py3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'parameters/14~conv2d/weights_32_32_3-0.npy'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def save_parameters(layer, name, input_shape_str, param_type, motif_id):\n",
    "    if param_type is \"weights\":\n",
    "        params = layer.get_weights()[0]\n",
    "    else:\n",
    "        params = layer.get_weights()[1]\n",
    "    params_filename = join(\"parameters\", str(motif_id) + \"~\" + name, param_type + \"_\" + input_shape_str + \"-0.npy\")\n",
    "    path = Path(params_filename)\n",
    "    \n",
    "    i = 1\n",
    "    while True:\n",
    "        if path.is_file():\n",
    "            params_filename = params_filename.split(\"-\")[0] + \"-%d\" % (i) + \".npy\"\n",
    "            path = Path(params_filename)\n",
    "        else:\n",
    "            np.save(params_filename, params)\n",
    "            break\n",
    "        i += 1\n",
    "    return params_filename\n",
    "\n",
    "from os.path import join, exists\n",
    "from os import mkdir\n",
    "\n",
    "parameter_inserts = []\n",
    "for layer in model.layers:\n",
    "    if layer.trainable:\n",
    "        name = \"\".join(layer.name.split(\"_\")[:-1])\n",
    "        if not exists(join(\"parameters\", name)):\n",
    "            mkdir(join(\"parameters\", name))\n",
    "        input_shape_str = \"_\".join(map(str, layer.input_shape[1:]))\n",
    "\n",
    "        weights_filename = save_parameters(layer, name, input_shape_str, \"weights\", 0)\n",
    "        biases_filename = save_parameters(layer, name, input_shape_str, \"biases\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
